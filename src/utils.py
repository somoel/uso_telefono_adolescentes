import pandas as pd
import numpy as np


def imprimir_separador(titulo: str = "", longitud: int = 60, caracter: str = "=") -> None:
    """
    Imprime un separador visual con un t√≠tulo opcional.

    Args:
        titulo: T√≠tulo a mostrar en el separador
        longitud: Longitud del separador
        caracter: Caracter para el separador
    """
    if titulo:
        print(f"\n{caracter * longitud}")
        print(f"{titulo.center(longitud)}")
        print(f"{caracter * longitud}")
    else:
        print(f"\n{caracter * longitud}")


def guardar_resultados_csv(df: pd.DataFrame, nombre_archivo: str, carpeta: str = "../data/") -> None:
    """
    Guarda un DataFrame en un archivo CSV.

    Args:
        df: DataFrame a guardar
        nombre_archivo: Nombre del archivo (sin extensi√≥n)
        carpeta: Carpeta donde guardar el archivo
    """
    ruta_completa = f"{carpeta}{nombre_archivo}.csv"
    df.to_csv(ruta_completa, index=False)
    print(f"‚úÖ Resultados guardados en: {ruta_completa}")


def obtener_resumen_datos(df: pd.DataFrame) -> dict:
    """
    Obtiene un resumen completo del DataFrame.

    Args:
        df: DataFrame a resumir

    Returns:
        Diccionario con resumen de datos
    """
    resumen = {
        'dimensiones': df.shape,
        'total_filas': len(df),
        'total_columnas': len(df.columns),
        'columnas': df.columns.tolist(),
        'tipos_datos': df.dtypes.to_dict(),
        'valores_nulos': df.isna().sum().to_dict(),
        'valores_duplicados': df.duplicated().sum(),
        'memoria_uso_mb': df.memory_usage(deep=True).sum() / 1024 ** 2
    }

    return resumen


def imprimir_resumen_datos(df: pd.DataFrame) -> None:
    """
    Imprime un resumen formateado del DataFrame.

    Args:
        df: DataFrame a resumir
    """
    resumen = obtener_resumen_datos(df)

    imprimir_separador("RESUMEN DEL DATASET")
    print(f"üìä Dimensiones: {resumen['dimensiones']}")
    print(f"üìà Total de filas: {resumen['total_filas']}")
    print(f"üìã Total de columnas: {resumen['total_columnas']}")
    print(f"üíæ Uso de memoria: {resumen['memoria_uso_mb']:.2f} MB")
    print(f"üî¢ Valores duplicados: {resumen['valores_duplicados']}")

    print(f"\nüìù Columnas:")
    for col in resumen['columnas']:
        print(f"   - {col}")

    print(f"\n‚ùå Valores nulos:")
    for col, nulos in resumen['valores_nulos'].items():
        if nulos > 0:
            print(f"   - {col}: {nulos}")

    if sum(resumen['valores_nulos'].values()) == 0:
        print("   ‚úÖ No hay valores nulos")

    imprimir_separador()


def exportar_metricas_modelo(metricas: dict, nombre_archivo: str, carpeta: str = "../data/") -> None:
    """
    Exporta las m√©tricas de un modelo a un archivo CSV.

    Args:
        metricas: Diccionario con m√©tricas del modelo
        nombre_archivo: Nombre del archivo (sin extensi√≥n)
        carpeta: Carpeta donde guardar el archivo
    """
    # Convertir report a DataFrame
    if 'classification_report' in metricas:
        report_df = pd.DataFrame(metricas['classification_report']).transpose()
        ruta_completa = f"{carpeta}{nombre_archivo}_report.csv"
        report_df.to_csv(ruta_completa)
        print(f"‚úÖ M√©tricas guardadas en: {ruta_completa}")

    # Guardar confusion matrix
    if 'confusion_matrix' in metricas:
        cm_df = pd.DataFrame(metricas['confusion_matrix'])
        ruta_cm = f"{carpeta}{nombre_archivo}_confusion_matrix.csv"
        cm_df.to_csv(ruta_cm, index=False)
        print(f"‚úÖ Matriz de confusi√≥n guardada en: {ruta_cm}")


def calcular_metricas_adicionales(y_true, y_pred) -> dict:
    """
    Calcula m√©tricas adicionales de evaluaci√≥n.

    Args:
        y_true: Valores reales
        y_pred: Valores predichos

    Returns:
        Diccionario con m√©tricas adicionales
    """
    from sklearn.metrics import precision_score, recall_score, f1_score

    metricas = {
        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),
        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),
        'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),
        'precision_weighted': precision_score(y_true, y_pred, average='weighted', zero_division=0),
        'recall_weighted': recall_score(y_true, y_pred, average='weighted', zero_division=0),
        'f1_weighted': f1_score(y_true, y_pred, average='weighted', zero_division=0)
    }

    return metricas
